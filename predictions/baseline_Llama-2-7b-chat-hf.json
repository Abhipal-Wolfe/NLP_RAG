{
  "chain_type": "baseline",
  "dataset": "original_repo/data/benchmark/med_qa_test.jsonl",
  "num_samples": 1273,
  "config": "BaselineConfig(model_path='meta-llama/Llama-2-7b-chat-hf', dtype='half', gpu_memory_utilization=0.7, max_model_len=4096, enforce_eager=True, temperature=0.0, max_tokens=200, top_p=1.0, use_few_shot=True, dataset_name='med_qa', use_substring_match=True, batch_size=8)",
  "metrics": {
    "substring_match": {
      "accuracy": 45.483110761979574,
      "correct": 579,
      "total": 1273
    },
    "exact_match": {
      "accuracy": 0.0,
      "correct": 0,
      "total": 1273
    },
    "primary_method": "substring_match"
  }
}