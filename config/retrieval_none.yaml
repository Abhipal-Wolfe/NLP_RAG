# Retrieval Ablation: No retrieval (baseline)

generator:
  type: VLLMGenerator
  model_path: "meta-llama/Llama-2-7b-hf"
  max_tokens: 200
  temperature: 0.0

retriever: null  # No retriever

augmentations:
  query: []
  retrieval: []
  rerank: []
  generation: []
  reflection: []

dataset: "eval_datasets/medqa_train.jsonl"
max_samples: 100
output_path: "experiments/results/retrieval_none"
