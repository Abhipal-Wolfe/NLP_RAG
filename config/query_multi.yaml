# Query Ablation: Multi-query expansion

generator:
  type: VLLMGenerator
  model_path: "meta-llama/Llama-2-7b-chat-hf"
  max_tokens: 200
  temperature: 0.0

retriever:
  type: FAISSRetriever
  top_k: 5

augmentations:
  query:
    - multi_query  # Query expansion
  retrieval: []
  rerank: []
  generation: []
  reflection: []

dataset: "test_data/med_qa_train.json"
max_samples: 100
output_path: "experiments/results/query_multi"
