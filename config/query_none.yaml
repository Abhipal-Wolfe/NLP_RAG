# Query Ablation: No query processing

generator:
  type: VLLMGenerator
  model_path: "meta-llama/Llama-2-7b-chat-hf"
  max_tokens: 200
  temperature: 0.0

retriever:
  type: FAISSRetriever
  top_k: 5

augmentations:
  query: []  # No query processing
  retrieval: []
  rerank: []
  generation: []
  reflection: []

dataset: "test_data/med_qa_train.json"
max_samples: 100
output_path: "experiments/results/query_none"
